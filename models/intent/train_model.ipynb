{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:48:58.748415Z",
     "start_time": "2024-06-15T07:48:50.453479Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.src.losses import loss\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "\n"
   ],
   "id": "859538c7f061a81c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:48:58.786871Z",
     "start_time": "2024-06-15T07:48:58.750426Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_file = \"total_train_data.csv\"\n",
    "data = pd.read_csv(train_file)\n",
    "intents = data['고객의도'].tolist()\n",
    "queries= data['고객질문(요청)'].tolist()\n",
    "\n"
   ],
   "id": "4e1e0e64c90cab4",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:49:04.553566Z",
     "start_time": "2024-06-15T07:48:58.788911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from utils.Preprocess import Preprocess\n",
    "p = Preprocess(word2index_dic='C:\\\\Users\\\\wmk51\\\\PycharmProjects\\\\LB_project\\\\train_tools\\\\dict\\\\chatbot_dict.bin',\n",
    "               userdic='C:\\\\Users\\\\wmk51\\\\PycharmProjects\\\\LB_project\\\\utils\\\\user_dic.tsv')"
   ],
   "id": "2ade10cfd5782650",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T07:49:12.036365Z",
     "start_time": "2024-06-15T07:49:10.618572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#단어 시퀀스 생성\n",
    "sequences = []\n",
    "for sentence in queries:\n",
    "    pos = p.pos(sentence)\n",
    "    keywords = p.get_keywords(pos, without_tag=True)\n",
    "    seq = p.get_wordidx_sequence(keywords)\n",
    "    sequences.append(seq)"
   ],
   "id": "6968a40e33f18f09",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:12:52.260949Z",
     "start_time": "2024-06-15T08:12:52.252509Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#단어 인덱스 시퀀스 벡터 생성\n",
    "#단어 시퀀스 벡터 생성\n",
    "from config.GlobalParams import MAX_SEQ_LEN\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN,padding='post')\n"
   ],
   "id": "43cc6a5d246556d0",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:19:01.399338Z",
     "start_time": "2024-06-15T08:18:57.594395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#학습용, 검증용, 테스트용, 데이터셋\n",
    "#학습셋:검증셋:테스트셋 = 7:2:1\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs,intents))\n",
    "ds = ds.shuffle(len(queries))\n",
    "\n",
    "train_size = int(len(padded_seqs)*0.7)\n",
    "val_size = int(len(padded_seqs)*0.2)\n",
    "test_size = len(padded_seqs)-train_size-val_size\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "#하이퍼파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(p.word_index) + 1\n",
    "\n",
    "#CNN 모델 정의\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE,EMB_SIZE)(input_layer)\n",
    "dropout_emb = Dropout(rate = dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(128, kernel_size=3, padding='valid', activation='relu')(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(128, kernel_size=3, padding='valid', activation='relu')(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding= 'valid',\n",
    "    activation = \"relu\"\n",
    ")(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "concat = concatenate([pool1,pool2,pool3])\n",
    "hidden = Dense(128, activation='relu')(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(4, name='logits')(dropout_hidden)\n",
    "predictions = Dense(4,activation='softmax')(logits)\n",
    "\n",
    "#모델 생성\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "## 타겟 데이터가 정수 이면 sparse_categorical_crossentropy 사용해야한다.\n",
    "model.compile(optimizer=\"adam\", loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#모델 학습\n",
    "\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1)\n",
    "\n",
    "#모델 평가\n",
    "loss, accuracy = model.evaluate(test_ds,verbose=1)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss: %f' % (loss))\n",
    "\n",
    "model.save('intent_model.h5')"
   ],
   "id": "7c06f6936ecfd5b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m3s\u001B[0m 34ms/step - accuracy: 0.2873 - loss: 1.3535 - val_accuracy: 0.3469 - val_loss: 1.2131\n",
      "Epoch 2/5\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.4631 - loss: 1.1520 - val_accuracy: 0.7245 - val_loss: 0.8397\n",
      "Epoch 3/5\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.6848 - loss: 0.8055 - val_accuracy: 0.8673 - val_loss: 0.5350\n",
      "Epoch 4/5\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 9ms/step - accuracy: 0.8062 - loss: 0.5804 - val_accuracy: 0.9184 - val_loss: 0.4004\n",
      "Epoch 5/5\n",
      "\u001B[1m18/18\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 8ms/step - accuracy: 0.8823 - loss: 0.4057 - val_accuracy: 0.9592 - val_loss: 0.2091\n",
      "\u001B[1m3/3\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 142ms/step - accuracy: 0.9045 - loss: 0.2939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.156863\n",
      "loss: 0.285709\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T08:12:53.335708Z",
     "start_time": "2024-06-15T08:12:53.301940Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8baebb46781c28b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3553, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Local\\Temp\\ipykernel_15388\\2506353997.py\", line 6, in <module>\n",
      "    model.fit(train_ds, validation_date= val_ds, epochs=EPOCH, verbose=1)\n",
      "  File \"C:\\Users\\wmk51\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 122, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"C:\\Users\\wmk51\\anaconda3\\envs\\chatbot\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 119, in error_handler\n",
      "    filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: TensorFlowTrainer.fit() got an unexpected keyword argument 'validation_date'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 2144, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1448, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1339, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1186, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1076, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\ultratb.py\", line 1173, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 283, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "  File \"C:\\Users\\wmk51\\AppData\\Roaming\\Python\\Python311\\site-packages\\executing\\executing.py\", line 80, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e40d97c5b7321594"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
